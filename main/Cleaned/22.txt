cyclic contrastive divergence learning algorithm high order rbms high order rbms cyclic contrastive divergence learning gradient approximation convergence upper bound restricted boltzmann machine rbm special case general boltzmann machine typical probabilistic graphical model attracted much attention recent year due it powerful ability extracting feature representing distribution underlying training data most commonly used algorithm learning rbms called contrastive divergence cd proposed by hinton which start markov chain data point run chain only few iteration get low variance estimator however when referring high order rbm since there interaction among it visible layer gradient approximation via cd learning usually becomes far from log likelihood gradient even may cause cd learning fall into infinite loop with high reconstruction error this paper new algorithm named cyclic contrastive divergence ccd introduced learning high order rbms unlike standard cd algorithm ccd update parameter according each visible layer turn by borrowing idea cyclic block coordinate descent method evaluate performance proposed ccd algorithm regarding high order rbms learning both algorithm ccd standard cd theoretically analyzed including convergence estimate upper bound both bias comparison from which superiority ccd learning revealed experiment handwritten digit classification task mnist dataset performed experimental result show that ccd more applicable consistently outperforms standard cd both convergent speed performance 