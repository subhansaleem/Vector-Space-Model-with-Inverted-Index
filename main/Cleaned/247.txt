assessing threat adversarial example deep neural network neural network security agriculture training machine learning mimic camera deep neural network facing potential security threat from adversarial example input that look normal but cause an incorrect classification by deep neural network example proposed threat could result hand written digit scanned check being incorrectly classified but looking normal when human see them this research ass extent which adversarial example pose security threat when one considers normal image acquisition process this process mimicked by simulating transformation that normally occur acquiring image real world application such using scanner acquire digit check amount or using camera an autonomous car these small transformation negate effect carefully crafted perturbation adversarial example resulting correct classification by deep neural network thus just acquiring image decrease potential impact proposed security threat also show that already widely used process averaging over multiple crop neutralizes most adversarial example normal preprocessing such text binarization almost completely neutralizes adversarial example this first paper show that text driven classification adversarial example an academic curiosity not security threat 