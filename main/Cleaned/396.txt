new framework fine tuning deep network deep learning deep neural network fine tuning drop out technique gain parameter drop out technique very often training deep neural network involves two learning phase unsupervised pretraining supervised fine tuning unsupervised pretraining used learn parameter deep neural network while supervised fine tuning improves upon what been learnt pretraining stage predominant algorithm that used supervised fine tuning deep neural network standard backpropagation algorithm however field shallow neural network number modification backpropagation algorithm been proposed that improved performance trained model this paper propose hybrid approach that integrates gain parameter based backpropagation algorithm dropout technique evaluate it effectiveness fine tuning deep neural network three benchmark datasets result indicate that proposed hybrid approach performs better fine tuning than backpropagation algorithm alone 