resampling based variable selection with lasso p n partially linear model feature selection variable selection big data high dimensional data lasso regression non linearity linear model regression function widely used perhaps most case highly unrealistic simplifying assumption when proposing consistent variable selection method large highly dimensional datasets this paper study what happens from theoretical point view when variable selection method assumes linear regression function underlying ground truth model composed linear non linear term that most partially linear demonstrate consistency lasso method when model partially linear however note that algorithm tends increase even more number selected false positive partially linear model when given few training sample that usually because value small group sample happen explain variation coming from non linear part response function noise using linear combination wrong predictor demonstrate theoretically that false positive likely selected by lasso method due small proportion sample which happen explain some variation response variable show that this property implies that if run lasso several slightly smaller size data replication sampled without replacement intersect result likely reduce number false positive without losing already selected true positive propose novel consistent variable selection algorithm based this property show it outperform other variable selection method synthetic datasets linear partially linear model datasets from uci machine learning repository 