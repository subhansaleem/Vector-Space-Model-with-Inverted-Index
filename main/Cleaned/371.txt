incomplet dot product dynam comput scale neural network infer machin learn approxim comput iot deep learn convolut neural network propos use incomplet dot product idp dynam adjust number input channel use each layer convolut neural network dure feedforward infer idp add monoton non increas coeffici refer profil channel dure train profil order contribut each channel non increas order infer time number channel use dynam adjust trade off accuraci lower power consumpt reduc latenc by select onli begin subset channel thi approach allow singl network dynam scale over comput rang oppos train deploy multipl network support differ level comput scale addit extend notion multipl profil each optim some specif rang comput scale present experi comput accuraci trade off idp popular imag classif model dataset demonstr that mnist cifar 10 idp reduc comput significantli e g by 75 without significantli compromis accuraci argu that idp provid conveni effect mean devic lower comput cost dynam reflect current comput budget system exampl vgg 16 with 50 idp use onli first 50 channel achiev 70 accuraci cifar 10 dataset compar standard network which achiev onli 35 accuraci when use reduc channel set 