automated optimal architecture deep convolutional neural network image recognition convolutional neural network cnns hyperparameter optimization deconvolutional network deconvnet nelder mead algorithm nma recent advancement deep convolutional neural network cnns led impressive progress computer vision especially image classification cnns involve numerous hyperparameters that identify network s structure such depth network kernel size number feature map stride pooling size pooling region etc these hyperparameters significant impact classification accuracy cnn selecting proper cnn architecture different from one dataset another an empirical approach often used determining near optimal value these hyperparameters some recent work tried optimization technique hyperparameter selection well this paper develop framework hyperparameter optimization that based new objective function that combine information from visualization learned feature map via deconvolutional network accuracy trained cnn model nelder mead algorithm nma used guiding cnn architecture towards near optimal hyperparameters our proposed approach evaluated cifar 10 caltech 101 benchmark experimental result indicate that final architecture cnn obtained by our objective function outperforms other approach term accuracy it shown that our optimization framework contributes increase depth network shrink size stride pooling size obtain best cnn architecture 