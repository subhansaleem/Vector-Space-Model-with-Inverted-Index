predicting future agent motion dynamic environment activity forecasting inverse reinforcement learning multiple object tracking understanding activity people monitored environment topic active research motivated by application requiring context awareness inferring future agent motion useful not only improving tracking accuracy but also planning an interactive motion task despite rapid advance area activity forecasting many state art method still cumbersome use realistic robot this due requirement having good semantic scene map labelling well assumption made regarding possible goal type motion many emerging application require robot with modest sensory computational ability robustly perform such activity forecasting high density dynamic environment address this by combining novel multi camera tracking method efficient multi resolution representation state standard inverse reinforcement learning irl technique demonstrate performance that better than state art literature this framework irl method us agent trajectory from distributed tracker estimate reward function within markov decision process mdp model this reward function then used estimate agent s motion future novel task instance present empirical experiment using data gathered our own lab external corpus virat based which find that our algorithm not only efficiently implementable resource constrained platform but also competitive term accuracy with state art alternative e g 20 better than result reported 1 