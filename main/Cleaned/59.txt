improved knn rule small training set error analysis training prediction algorithm data model computer science educational institution electronic mail traditional k nn classification rule predicts label based most common label k nearest neighbor plurality rule it known that plurality rule optimal when number example tends infinity this paper show that plurality rule sub optimal when number label large number example small propose simple k nn rule that take into account label neighbor rather than just most common label present number experiment both synthetic datasets real world datasets including mnist svhn show that our new rule achieve lower error rate compared majority rule many case 