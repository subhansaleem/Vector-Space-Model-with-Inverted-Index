parametric exponential linear unit deep convolutional neural network activation function deep learning object recognition an important task improving ability visual system perform complex scene understanding recently exponential linear unit elu been proposed key component managing bias shift convolutional neural network cnns but defines parameter that must set by hand this paper propose learning parameterization elu order learn proper activation shape each layer cnns our result mnist cifar 10 100 imagenet datasets using nin overfeat cnn resnet network indicate that our proposed parametric elu pelu better performance than non parametric elu observed much 7 28 relative error improvement imagenet with nin network with only 0 0003 parameter increase our visual examination non linear behavior adopted by vgg using pelu show that network took advantage added flexibility by learning different activation different layer 