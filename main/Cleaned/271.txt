bayesian unification gradient bandit based learning accelerated global optimisation global optimization multi armed bandit line learning multi strategy learning bandit based optimisation scheme remarkable advantage over gradient based approach due their global perspective which eliminates danger getting stuck local optimum however continuous optimisation problem or problem with large number action bandit based approach hindered by slow learning gradient based approach other hand navigate quickly high dimensional continuous space through local optimisation following gradient fine grained step however apart from being susceptible local optimum these scheme also le suited online learning due their reliance extensive trial error before optimum identified contrast bandit algorithm seek identify optimal action global optimum few step possible this paper propose bayesian approach that unifies above two distinct paradigm one single framework with aim combining their advantage heart our approach find stochastic linear approximation function optimised where both gradient value function explicitly captured this model allows u learn from both noisy function gradient observation well predicting these property across action space support optimisation further propose an accompanying bandit driven exploration scheme that us bayesian credible bound trade off exploration against exploitation our empirical result demonstrate that by unifying bandit gradient based learning one obtains consistently improved performance across wide spectrum problem environment furthermore even when gradient feedback unavailable flexibility our model including gradient prediction still allows u outperform competing approach although with smaller margin 