effect dataset size train tweet sentiment classifi sentiment analysi tweet mine classif big data use autom method label tweet sentiment larg volum tweet label use train classifi million tweet could use train classifi howev do so comput expens thu it valuabl establish how mani tweet should util train classifi sinc use addit instanc with gain perform wast resourc thi studi seek find out how mani tweet need befor signific improv observ sentiment analysi when ad addit instanc train evalu classifi use c4 5 decis tree naïv bay 5 nearest neighbor radial basi function network with seven dataset vari from 1000 243 000 instanc model train use four run 5 fold cross valid addit conduct statist test verifi our observ examin impact limit featur use frequenc learner were found improv with dataset size with naïv bay be best perform learner found that naïv bay did not significantli benefit from use more than 81 000 instanc best our knowledg thi first studi investig how learner scale respect dataset size with result verifi use statist test multipl model train each learner dataset size addit investig use featur frequenc greatli reduc data grid size with either small increas or decreas classifi perform depend choic learner 